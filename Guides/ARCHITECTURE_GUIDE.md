# Guide Architecture SOLID & LLM - A-IR-DD2

> **Objectif** : RÃ©fÃ©rence complÃ¨te de l'architecture logicielle, patterns SOLID/DDD, et gestion fine des spÃ©cificitÃ©s LLM.

---

## ğŸ—ï¸ Architecture Globale

### SÃ©paration Domain-Driven Design (DDD)

L'application respecte une **sÃ©paration stricte** entre deux domaines :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DESIGN DOMAIN                      â”‚
â”‚  ResponsabilitÃ© : Prototypes, dÃ©finitions statiques â”‚
â”‚  Store : useDesignStore (Zustand)                   â”‚
â”‚  Fichiers : types.ts, agentTemplates.ts             â”‚
â”‚  Persistence : JSON-serializable                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†•ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 RUNTIME DOMAIN                      â”‚
â”‚  ResponsabilitÃ© : ExÃ©cution, Ã©tats volatiles        â”‚
â”‚  Store : useRuntimeStore (Zustand)                  â”‚
â”‚  Fichiers : services/*, V2AgentNode.tsx             â”‚
â”‚  Persistence : In-memory, WebSocket sync            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âš ï¸ RÃ¨gle Critique** : Ne JAMAIS mÃ©langer les responsabilitÃ©s.  
âŒ Mauvais : Stocker l'Ã©tat d'exÃ©cution dans les prototypes  
âœ… Bon : Prototype (Design) â†’ Instance (Runtime)

---

## ğŸ“ Principes SOLID AppliquÃ©s

### S - Single Responsibility Principle

**Chaque service a UNE responsabilitÃ©** :

```typescript
// âœ… BON : Service dÃ©diÃ© par provider
// openAIService.ts
export const generateContentStream = async (apiKey, model, systemInstruction, history, tools, outputConfig)
export const generateImage = async (apiKey, prompt)

// geminiService.ts
export const generateContentStream = async (apiKey, model, systemInstruction, history, tools, outputConfig)
export const generateContentWithSearch = async (apiKey, model, prompt, systemInstruction)

// âŒ MAUVAIS : Service monolithique
// llmService.ts (si tout Ã©tait dedans)
export const doEverything = async (provider, ...) { /* 1000 lignes */ }
```

### O - Open/Closed Principle

**Ouvert Ã  l'extension, fermÃ© Ã  la modification** :

#### Exemple : Ajout d'un nouveau LLM

1. **CrÃ©er le service** : `services/newLLMService.ts`
2. **ImplÃ©menter le contrat** :
   ```typescript
   export const generateContentStream = async function* (...) { /* implÃ©mentation */ }
   export const generateContent = async (...) { /* implÃ©mentation */ }
   // Optionnel :
   export const generateImage = async (...) { /* si supportÃ© */ }
   ```
3. **Enregistrer dans dispatcher** : `services/llmService.ts`
   ```typescript
   switch (provider) {
     case LLMProvider.NewLLM:
       return newLLMService.generateContentStream(...);
   }
   ```
4. **DÃ©clarer capabilities** : `llmModels.ts`
   ```typescript
   [LLMProvider.NewLLM]: {
     [LLMCapability.Chat]: true,
     [LLMCapability.FunctionCalling]: true,
     // ...
   }
   ```

**Aucune modification des composants UI** â†’ Capabilities-driven rendering.

### L - Liskov Substitution Principle

**Tous les services LLM respectent le mÃªme contrat** :

```typescript
// Contrat implicite (Ã  formaliser en interface TS)
interface LLMService {
  generateContentStream(
    apiKey: string,
    model: string,
    systemInstruction: string,
    history: ChatMessage[],
    tools?: Tool[],
    outputConfig?: OutputConfig
  ): AsyncGenerator<StreamChunk>;

  generateContent(
    apiKey: string,
    model: string,
    systemInstruction: string,
    history: ChatMessage[],
    tools?: Tool[],
    outputConfig?: OutputConfig
  ): Promise<{ text: string; toolCalls?: ToolCall[] }>;

  // Optionnel
  generateImage?(apiKey: string, prompt: string): Promise<{ image?: string; error?: string }>;
  generateContentWithSearch?(apiKey: string, model: string, prompt: string, systemInstruction: string): Promise<{ text: string }>;
}
```

**Substitution** : `openAIService` peut Ãªtre remplacÃ© par `geminiService` sans casser le code appelant.

### I - Interface Segregation Principle

**Pas d'interface monolithique** :

```typescript
// âœ… BON : Capabilities granulaires
enum LLMCapability {
  Chat,
  ImageGeneration,
  ImageModification,
  WebSearch,
  // ...
}

// Chaque LLM dÃ©clare ce qu'il PEUT faire
const geminiCapabilities = {
  [LLMCapability.Chat]: true,
  [LLMCapability.ImageGeneration]: true,
  [LLMCapability.WebSearch]: true,
};

// âŒ MAUVAIS : Interface forcÃ©e
interface ForcedLLM {
  chat(): void;
  generateImage(): void; // Obligatoire mÃªme si non supportÃ©
  search(): void;
}
```

### D - Dependency Inversion Principle

**DÃ©pendre d'abstractions, pas de concrÃ©tions** :

```typescript
// âœ… BON : V2AgentNode dÃ©pend de LLMCapability (abstraction)
{agent.capabilities?.includes(LLMCapability.ImageGeneration) && (
  <Button onClick={handleOpenImagePanel}>
    <ImageIcon />
  </Button>
)}

// âŒ MAUVAIS : DÃ©pendre de provider concret
{agent.llmProvider === LLMProvider.Gemini && (
  <Button>Generate Image</Button>
)}
```

---

## ğŸ§© Patterns de Conception (GoF)

### Factory Pattern (implicit)

**llmService.ts** agit comme Factory :

```typescript
export const generateContentStream = function* (provider, ...) {
  switch (provider) {
    case LLMProvider.OpenAI:
      return openAIService.generateContentStream(...);
    case LLMProvider.Gemini:
      return geminiService.generateContentStream(...);
    // ...
  }
};
```

### Strategy Pattern

**OutputConfig** permet de changer la stratÃ©gie de formatage :

```typescript
interface OutputConfig {
  format?: 'json' | 'markdown' | 'plain';
  schema?: JSONSchema;
  strictMode?: boolean;
}

// Le service LLM adapte son comportement selon la stratÃ©gie
if (outputConfig?.format === 'json') {
  systemInstruction += "\nRespond ONLY with valid JSON matching this schema...";
}
```

### Observer Pattern

**Zustand stores** implÃ©mentent le pattern Observer :

```typescript
// Composants "observent" le store
const messages = useRuntimeStore(state => state.nodeMessages[nodeId]);

// Changement d'Ã©tat notifie automatiquement les observateurs
addNodeMessage(nodeId, message); // â†’ V2AgentNode re-render
```

### Adapter Pattern

**pythonExecutor.ts** adapte l'interface subprocess au contrat Tool :

```typescript
// Contrat Tool : { name, parameters, description }
// Interface subprocess : stdin/stdout/stderr

export const executePythonTool = async (toolName: string, args: any): Promise<any> => {
  const result = await execFile('python3', [scriptPath, JSON.stringify(args)]);
  return JSON.parse(result.stdout); // Adaptation subprocess â†’ JSON
};
```

---

## ğŸ”€ Gestion Multi-LLM

### Architecture Dispatcher

**llmService.ts** centralise le routing :

```typescript
// Point d'entrÃ©e unique
export const generateContentStream = function* (provider: LLMProvider, ...) {
  // Validation provider
  if (!Object.values(LLMProvider).includes(provider)) {
    throw new Error(`Unknown provider: ${provider}`);
  }

  // Dispatch vers service spÃ©cialisÃ©
  switch (provider) {
    case LLMProvider.OpenAI:
      yield* openAIService.generateContentStream(...);
      break;
    case LLMProvider.Gemini:
      yield* geminiService.generateContentStream(...);
      break;
    // ...
  }
};
```

### Normalisation des Messages

**ProblÃ¨me** : Chaque LLM a son format de message.

**Solution** : Type `ChatMessage` commun + adaptation dans chaque service.

```typescript
// Format interne (types.ts)
interface ChatMessage {
  id: string;
  sender: 'user' | 'agent' | 'tool' | 'tool_result';
  text: string;
  image?: string;
  toolCalls?: ToolCall[];
}

// Adaptation OpenAI
const openAIMessages = history.map(msg => ({
  role: msg.sender === 'user' ? 'user' : 'assistant',
  content: msg.text,
  tool_calls: msg.toolCalls?.map(adaptToolCall)
}));

// Adaptation Gemini
const geminiMessages = history.map(msg => ({
  role: msg.sender === 'user' ? 'user' : 'model',
  parts: [{ text: msg.text }]
}));
```

### Gestion des Capabilities

**DÃ©claration centralisÃ©e** : `llmModels.ts`

```typescript
export const LLM_MODELS: Record<LLMProvider, { [key in LLMCapability]?: boolean }> = {
  [LLMProvider.Gemini]: {
    [LLMCapability.Chat]: true,
    [LLMCapability.FileUpload]: true,
    [LLMCapability.ImageGeneration]: true,
    [LLMCapability.ImageModification]: true,
    [LLMCapability.WebSearch]: true,
    [LLMCapability.FunctionCalling]: true,
  },
  [LLMProvider.DeepSeek]: {
    [LLMCapability.Chat]: true,
    [LLMCapability.FunctionCalling]: true,
    [LLMCapability.Reasoning]: true, // SpÃ©cificitÃ© DeepSeek
    [LLMCapability.CacheOptimization]: true,
  },
  [LLMProvider.LMStudio]: {
    [LLMCapability.Chat]: true,
    [LLMCapability.LocalDeployment]: true, // SpÃ©cificitÃ© LMStudio
    [LLMCapability.CodeSpecialization]: true,
  },
};
```

**Consommation dans UI** :

```typescript
const agent = {
  llmProvider: LLMProvider.Gemini,
  capabilities: LLM_MODELS[LLMProvider.Gemini]
};

// Rendering conditionnel
{agent.capabilities[LLMCapability.ImageGeneration] && <ImageButton />}
```

---

## ğŸ”§ SpÃ©cificitÃ©s LLM par Provider

### OpenAI

**Streaming** : Server-Sent Events (SSE)
```typescript
const response = await fetch('https://api.openai.com/v1/chat/completions', {
  body: JSON.stringify({ stream: true, ... })
});
const reader = response.body.getReader();
for await (const chunk of readChunks(reader)) {
  // Parsing "data: {...}\n\n"
  yield JSON.parse(chunk);
}
```

**Function Calling** : Format JSON strict
```typescript
tools: [{
  type: 'function',
  function: {
    name: 'textAnalysis',
    parameters: { /* JSON Schema */ }
  }
}]
```

**Image Generation** : DALL-E endpoint sÃ©parÃ©
```typescript
POST /v1/images/generations
{ prompt: "...", size: "1024x1024" }
```

### Gemini (Google)

**Streaming** : `streamGenerateContent`
```typescript
const result = await model.generateContentStream({
  contents: [{ role: 'user', parts: [{ text: prompt }] }],
  tools: [{ functionDeclarations: [...] }]
});
for await (const chunk of result.stream) {
  yield chunk.text();
}
```

**Web Search** : Capability native via `tools`
```typescript
tools: [{ googleSearchRetrieval: {} }]
```

**Image Modification** : `editImage` API
```typescript
const result = await model.generateContent({
  contents: [{
    role: 'user',
    parts: [
      { inlineData: { mimeType: 'image/png', data: base64 } },
      { text: 'Make background blurred' }
    ]
  }]
});
```

### Anthropic (Claude)

**Messages API** : Format propriÃ©taire
```typescript
{
  model: 'claude-3-5-sonnet-20241022',
  messages: [{ role: 'user', content: '...' }],
  system: 'System prompt...' // SÃ©parÃ© de messages
}
```

**Tool Use** : Beta feature
```typescript
headers: { 'anthropic-version': '2023-06-01', 'anthropic-beta': 'tools-2024-04-04' }
tools: [{ name: '...', input_schema: { /* JSON Schema */ } }]
```

### DeepSeek

**Reasoning Mode** : ModÃ¨les spÃ©cialisÃ©s
```typescript
model: 'deepseek-reasoner' // vs 'deepseek-chat'
// Retourne "thinking" process avant rÃ©ponse finale
```

**Cache Optimization** : Prompt caching
```typescript
// RÃ©utilise les prompts systÃ¨me frÃ©quents pour rÃ©duire coÃ»ts
cache_key: hash(systemInstruction)
```

### LMStudio (Local)

**Endpoint Custom** : API compatible OpenAI
```typescript
const baseURL = llmConfig.apiKey; // Ex: "http://localhost:3928"
// Utilise openAIService avec baseURL custom
```

**Model Discovery** : `/v1/models` endpoint
```typescript
const models = await fetch(`${baseURL}/v1/models`).then(r => r.json());
// Liste modÃ¨les disponibles localement
```

### Mistral

**Embedding** : ModÃ¨les dÃ©diÃ©s
```typescript
model: 'mistral-embed'
// Retourne vecteurs pour RAG
```

**OCR** : Support images
```typescript
content: [
  { type: 'image_url', image_url: { url: `data:image/png;base64,${base64}` } },
  { type: 'text', text: 'Extract text from this image' }
]
```

### Perplexity

**Web Search Natif** : Toutes requÃªtes font recherche
```typescript
model: 'pplx-70b-online' // vs 'pplx-70b-chat'
// Retourne sources avec rÃ©ponse
response: { text: '...', citations: ['url1', 'url2'] }
```

### Qwen (Alibaba)

**Multimodal** : Support image/audio/video
```typescript
content: [
  { type: 'file', file_url: 'https://...' },
  { type: 'text', text: 'Analyze this video' }
]
```

### Kimi (Moonshot)

**Long Context** : 200k tokens
```typescript
model: 'moonshot-v1-128k' // ou 'moonshot-v1-32k'
// OptimisÃ© pour documents longs
```

### Grok (xAI)

**Real-time Data** : AccÃ¨s X/Twitter
```typescript
// Capability implicite : donnÃ©es temps rÃ©el
response: { text: '...', timestamp: '...' }
```

---

## ğŸ—‚ï¸ Structure des Stores Zustand

### useDesignStore (Design Domain)

```typescript
interface DesignStore {
  // Prototypes (statiques)
  agentPrototypes: AgentPrototype[];
  connectionPrototypes: ConnectionPrototype[];
  eventPrototypes: EventPrototype[];
  
  // Instances (rÃ©fÃ©rences)
  agentInstances: AgentInstance[]; // { id, prototypeId, position }
  
  // Actions CRUD
  addAgentPrototype: (prototype: AgentPrototype) => void;
  updateAgentPrototype: (id: string, updates: Partial<AgentPrototype>) => void;
  deleteAgentPrototype: (id: string) => void;
  
  // Validation intÃ©gritÃ©
  validateWorkflowIntegrity: () => ValidationResult;
  cleanupOrphanedInstances: () => void;
}
```

### useRuntimeStore (Runtime Domain)

```typescript
interface RuntimeStore {
  // Ã‰tats volatiles
  nodeMessages: Record<string, ChatMessage[]>; // nodeId â†’ messages
  executingNodes: Set<string>;
  
  // Configuration LLM (runtime)
  llmConfigs: LLMConfig[];
  
  // UI State
  isImagePanelOpen: boolean;
  currentImageNodeId: string | null;
  fullscreenImage: { src: string; mimeType: string } | null;
  
  // Actions
  addNodeMessage: (nodeId: string, message: ChatMessage) => void;
  setNodeMessages: (nodeId: string, messages: ChatMessage[]) => void;
  clearNodeMessages: (nodeId: string) => void;
  
  setNodeExecuting: (nodeId: string, isExecuting: boolean) => void;
}
```

**Synchronisation** : App.tsx maintient la cohÃ©rence entre les deux stores.

```typescript
// App.tsx
const handleImageGenerated = (nodeId: string, imageBase64: string) => {
  const imageMessage: ChatMessage = { /* ... */ };
  
  // Double mise Ã  jour
  handleUpdateNodeMessages(nodeId, prev => [...prev, imageMessage]); // React state (legacy)
  addNodeMessage(nodeId, imageMessage); // Zustand store (V2)
};
```

---

## ğŸ”€ Workflow de Tool Execution

### 1. DÃ©claration Tool (Agent Config)

```typescript
const agent: Agent = {
  tools: ['textAnalysis', 'imageProcessing'],
  // ...
};
```

### 2. Transmission au LLM

```typescript
// Dans service LLM
const tools = agent.tools.map(toolName => ({
  type: 'function',
  function: {
    name: toolName,
    description: TOOL_DESCRIPTIONS[toolName],
    parameters: TOOL_SCHEMAS[toolName]
  }
}));

const response = await llm.chat({ tools, ... });
```

### 3. LLM retourne Tool Call

```typescript
// Streaming chunk
{
  type: 'tool_call',
  toolCall: {
    id: 'call_abc123',
    name: 'textAnalysis',
    arguments: '{"text": "Analyze this"}'
  }
}
```

### 4. ExÃ©cution Backend

```typescript
// V2AgentNode.tsx dÃ©tecte tool call
if (chunk.response?.toolCall) {
  const result = await fetch('/api/execute-python-tool', {
    method: 'POST',
    body: JSON.stringify({
      toolName: chunk.response.toolCall.name,
      args: JSON.parse(chunk.response.toolCall.arguments)
    })
  });
}
```

### 5. Backend exÃ©cute Python

```typescript
// backend/src/server.ts
app.post('/api/execute-python-tool', async (req, res) => {
  const { toolName, args } = req.body;
  
  // Validation whitelist
  if (!WHITELISTED_PYTHON_TOOLS.includes(toolName)) {
    return res.status(403).json({ error: 'Tool not whitelisted' });
  }
  
  // ExÃ©cution
  const result = await executePythonTool(toolName, args);
  res.json({ result });
});
```

### 6. RÃ©sultat retournÃ© au LLM

```typescript
// Ajouter tool_result au chat
const toolResultMessage: ChatMessage = {
  sender: 'tool_result',
  text: JSON.stringify(result),
  toolCallId: chunk.response.toolCall.id
};

// Re-streaming avec rÃ©sultat
const finalResponse = await llm.chat({
  messages: [...history, userMessage, toolCallMessage, toolResultMessage]
});
```

---

## ğŸ›¡ï¸ Gouvernance & SÃ©curitÃ©

### Validation creator_id

```typescript
// governanceService.ts
export const validatePrototypeCreator = (prototype: Prototype): boolean => {
  const rules = {
    agent: ['archi'],
    connection: ['com'],
    event: ['tim'],
    dataTransform: ['phil']
  };
  
  return rules[prototype.type]?.includes(prototype.creator_id);
};
```

### Sanitization entrÃ©es utilisateur

```typescript
// Avant envoi au LLM
const sanitizeInput = (input: string): string => {
  return input
    .replace(/<script>/gi, '') // XSS
    .replace(/`{3,}/g, '```')  // Injection Markdown
    .trim();
};
```

### Rate Limiting (prÃ©vu)

```typescript
// timService.ts (futur)
export const checkRateLimit = (agentId: string): boolean => {
  const config = rateLimitConfigs[agentId];
  const calls = callHistory[agentId] || [];
  
  const recentCalls = calls.filter(
    timestamp => Date.now() - timestamp < config.windowMs
  );
  
  return recentCalls.length < config.maxCalls;
};
```

---

## ğŸ“¦ Organisation des Fichiers

```
Dev/
â”œâ”€â”€ components/           # UI Components (Atomic Design)
â”‚   â”œâ”€â”€ V2AgentNode.tsx  # Node workflow (Runtime)
â”‚   â”œâ”€â”€ IconSidebar.tsx  # Navigation verticale (Design)
â”‚   â”œâ”€â”€ modals/          # Dialogs
â”‚   â”œâ”€â”€ panels/          # Slide-over panels
â”‚   â””â”€â”€ workflow/        # React Flow custom nodes
â”‚
â”œâ”€â”€ contexts/            # React Contexts
â”‚   â”œâ”€â”€ LocalizationContext.tsx
â”‚   â”œâ”€â”€ NotificationContext.tsx
â”‚   â””â”€â”€ WorkflowCanvasContext.tsx
â”‚
â”œâ”€â”€ services/            # Business Logic (Runtime Domain)
â”‚   â”œâ”€â”€ llmService.ts    # Dispatcher
â”‚   â”œâ”€â”€ openAIService.ts # Provider OpenAI
â”‚   â”œâ”€â”€ geminiService.ts # Provider Gemini
â”‚   â””â”€â”€ governanceService.ts # Validation rÃ¨gles
â”‚
â”œâ”€â”€ stores/              # State Management (DDD)
â”‚   â”œâ”€â”€ useDesignStore.ts   # Design Domain
â”‚   â””â”€â”€ useRuntimeStore.ts  # Runtime Domain
â”‚
â”œâ”€â”€ types.ts             # Contrats de donnÃ©es (DDD)
â”œâ”€â”€ llmModels.ts         # Configuration capabilities
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ server.ts           # Express API
â”‚       â”œâ”€â”€ pythonExecutor.ts   # Tool execution
â”‚       â””â”€â”€ config.ts           # Whitelist
â”‚
â”œâ”€â”€ Guides/              # Documentation architecture
â”‚   â”œâ”€â”€ UX_FEATURES_GUIDE.md
â”‚   â””â”€â”€ ARCHITECTURE_GUIDE.md
â”‚
â””â”€â”€ documentation/       # Analyses & specs
    â”œâ”€â”€ PLAN_JALONS_SYNTHETIQUE.md
    â””â”€â”€ LLM_COMPATIBILITY_REPORT.md
```

---

## ğŸ§ª Testing Strategy (Ã  implÃ©menter)

### Tests Unitaires (Vitest)

```typescript
// services/__tests__/llmService.test.ts
describe('llmService.generateContentStream', () => {
  it('should dispatch to correct provider', async () => {
    const mockOpenAI = vi.spyOn(openAIService, 'generateContentStream');
    
    await llmService.generateContentStream(LLMProvider.OpenAI, ...);
    
    expect(mockOpenAI).toHaveBeenCalled();
  });
});
```

### Tests d'IntÃ©gration

```typescript
// __tests__/integration/imageWorkflow.test.tsx
describe('Image Generation Workflow', () => {
  it('should generate and add image to chat', async () => {
    render(<App />);
    
    // Clic icÃ´ne image
    fireEvent.click(screen.getByLabelText('Generate Image'));
    
    // Remplir prompt
    fireEvent.change(screen.getByLabelText('Prompt'), { target: { value: 'Cat' } });
    fireEvent.click(screen.getByText('Generate'));
    
    // Attendre gÃ©nÃ©ration (mock)
    await waitFor(() => {
      expect(screen.getByAltText('Generated Image')).toBeInTheDocument();
    });
    
    // Ajouter au chat
    fireEvent.click(screen.getByText('Add to Chat'));
    
    expect(screen.getByRole('img', { name: 'Image' })).toBeInTheDocument();
  });
});
```

### Tests E2E (Playwright)

```typescript
// e2e/workflow.spec.ts
test('complete agent workflow', async ({ page }) => {
  await page.goto('http://localhost:5173');
  
  // CrÃ©er agent
  await page.click('[aria-label="Archi"]');
  await page.click('text=CrÃ©er Prototype');
  await page.fill('input[name="name"]', 'Test Agent');
  await page.selectOption('select[name="llmProvider"]', 'Gemini');
  await page.click('button:has-text("CrÃ©er")');
  
  // Ajouter au workflow
  await page.click('text=Ajouter au Workflow');
  
  // VÃ©rifier prÃ©sence sur canvas
  await expect(page.locator('.react-flow__node')).toBeVisible();
});
```

---

## ğŸš€ Performance Optimizations

### React Flow Memoization

```typescript
// WorkflowCanvas.tsx
const NODE_TYPES = {
  v2Agent: V2AgentNode,
  customAgent: CustomAgentNode
};

// âŒ MAUVAIS : RecrÃ©ation Ã  chaque render
const nodeTypes = useMemo(() => ({ v2Agent: V2AgentNode }), []);

// âœ… BON : Constant globale
<ReactFlow nodeTypes={NODE_TYPES} />
```

### Streaming Optimization

```typescript
// Services LLM : Yield chunks dÃ¨s rÃ©ception
export async function* generateContentStream(...) {
  for await (const rawChunk of apiStream) {
    yield parseChunk(rawChunk); // Pas d'accumulation
  }
}
```

### Image Base64 Lazy Loading

```typescript
// V2AgentNode.tsx : Render preview seulement si visible
{isMinimized ? null : message.image && (
  <img src={`data:${message.mimeType};base64,${message.image}`} />
)}
```

---

## ğŸ“Š Monitoring & Observability (prÃ©vu V2)

### Telemetry LLM

```typescript
interface LLMTelemetry {
  provider: LLMProvider;
  model: string;
  tokens: { prompt: number; completion: number; total: number };
  latency: number; // ms
  cost: number; // USD
  success: boolean;
  error?: string;
}

export const trackLLMCall = (telemetry: LLMTelemetry) => {
  // Envoyer Ã  backend analytics
  fetch('/api/telemetry', {
    method: 'POST',
    body: JSON.stringify(telemetry)
  });
};
```

### Error Tracking

```typescript
// Sentry integration
import * as Sentry from '@sentry/react';

Sentry.init({
  dsn: process.env.VITE_SENTRY_DSN,
  integrations: [new Sentry.BrowserTracing()],
  tracesSampleRate: 0.1,
});

// Usage dans services
try {
  await llm.generateContent(...);
} catch (error) {
  Sentry.captureException(error, {
    tags: { provider: LLMProvider.OpenAI },
    contexts: { llm: { model, prompt } }
  });
}
```

---

## ğŸ”„ Migration Path V1 â†’ V2

### Phase 1 : Dual State (Actuel)

```typescript
// App.tsx maintient les deux
const [workflowNodes, setWorkflowNodes] = useState<WorkflowNode[]>([]); // V1
const { addNodeMessage } = useRuntimeStore(); // V2

// Double mise Ã  jour
handleUpdateNodeMessages(nodeId, ...); // V1
addNodeMessage(nodeId, message); // V2
```

### Phase 2 : Migration progressive

1. **Backend d'abord** : Migrer API vers stores
2. **UI ensuite** : Remplacer `workflowNodes` state par `useDesignStore`
3. **Cleanup** : Supprimer double Ã©criture

### Phase 3 : WebSocket Sync

```typescript
// services/webSocketService.ts
export const syncWorkflowState = (workflowId: string) => {
  const ws = new WebSocket(`ws://backend/workflow/${workflowId}`);
  
  ws.onmessage = (event) => {
    const { type, payload } = JSON.parse(event.data);
    
    switch (type) {
      case 'node_message':
        addNodeMessage(payload.nodeId, payload.message);
        break;
      case 'prototype_updated':
        updateAgentPrototype(payload.id, payload.updates);
        break;
    }
  };
};
```

---

## ğŸ“š RÃ©fÃ©rences & Ressources

### SOLID Principles
- Martin, Robert C. "Clean Architecture" (2017)
- Feathers, Michael. "Working Effectively with Legacy Code" (2004)

### Domain-Driven Design
- Evans, Eric. "Domain-Driven Design" (2003)
- Vernon, Vaughn. "Implementing Domain-Driven Design" (2013)

### LLM Best Practices
- OpenAI Cookbook: https://cookbook.openai.com
- Anthropic Claude Docs: https://docs.anthropic.com
- Google AI Studio: https://ai.google.dev

### React Patterns
- React Flow Docs: https://reactflow.dev
- Zustand Patterns: https://docs.pmnd.rs/zustand

---

**DerniÃ¨re mise Ã  jour** : 13 novembre 2025  
**Version** : V2.0 (Architecture 5 Robots + DDD)  
**Auteur** : ARC-1 (Agent IA Architecte)
